{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd5ffec90738522",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# LLM-Reasoners Demo\n",
    "\n",
    "This notebook is accompanied with our tutorial at SIGIR VF:\n",
    "[[slides](https://www.llm-reasoners.net/2024-02-Reasoners-SIGIR.pdf)]\n",
    "[[video](https://www.youtube.com/watch?v=d_x2pzEHGQY&pp=ygUJc2hpYm8gaGFv) (starting at 37:20)]\n",
    "\n",
    "## Setup\n",
    "Set cuda device and initialize an ExllamaModel use our unified LLM interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "94974910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pddl==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97a9dc24f71ab121",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1baf72f047599ea3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from reasoners.lm import ExLlamaModel, OpenAIModel\n",
    "import torch\n",
    "\n",
    "# https://huggingface.co/TheBloke/Llama-2-7B-Chat-GPTQ\n",
    "\n",
    "# model = ExLlamaModel(model_dir='/data/haotian/RAP_tune/Llama-2-70B-GPTQ',\n",
    "#                      lora_dir=None,\n",
    "#                      device = torch.device(\"cuda:0\"),\n",
    "#                      max_batch_size=1,\n",
    "#                      max_new_tokens=200,\n",
    "#                      mem_map=[16,22], # For 2 * 24GB GPUs. If you have > 40GB you can set it to None\n",
    "#                      max_seq_length=2048)\n",
    "\n",
    "# Or use any other model providers:\n",
    "\n",
    "# HFModel(llama_path, llama_path, device=device, max_batch_size=1, max_new_tokens=512, quantized=quantized, peft_pth=peft_path, load_awq_pth=load_awq_pth)\n",
    "# Llama3Model(llama2_ckpts, llama_size, max_batch_size=1)\n",
    "# OpenAIModel(openai_mode)\n",
    "# ClaudeModel('claude-3-opus-20240229')\n",
    "\n",
    "model = OpenAIModel(model=\"gpt-4o-us-east-1\", use_azure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d793476fcd72d193",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We gather one example from the Blocksworld dataset, and the proper prompt for in-context learning examples.\n",
    "We will talk more about Evaluators later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "48ab7cb1a4514699",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from reasoners.benchmark import BWEvaluator\n",
    "import json\n",
    "\n",
    "with open('examples/CoT/blocksworld/prompts/pool_prompt_v1.json') as f:\n",
    "    prompt = json.load(f)\n",
    "evaluator = BWEvaluator(config_file='examples/CoT/blocksworld/data/bw_config.yaml',\n",
    "                        domain_file='examples/CoT/blocksworld/data/generated_domain.pddl',\n",
    "                        data_path='examples/CoT/blocksworld/data/split_v1/split_v1_step_4_data.json',\n",
    "                        init_prompt=prompt)\n",
    "prompt = evaluator.sample_prompt(shuffle_prompt=False, num_shot=4)\n",
    "example = evaluator.full_dataset[1]\n",
    "cot_inputs = (prompt['icl'].replace('<init_state>', example[\"init\"])\n",
    "                           .replace('<goals>', example[\"goal\"])\n",
    "                           .replace('<action>', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc49cab381592729",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here is the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ab7d17be8373ae3e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the blue block is clear, the orange block is clear, the hand is empty, the orange block is on top of the red block, the red block is on the table and the blue block is on the table\n"
     ]
    }
   ],
   "source": [
    "print(example['init'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7d42ef78fea3bcfc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the red block is on top of the blue block\n"
     ]
    }
   ],
   "source": [
    "print(example['goal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7540875d5de58b5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Chain-of-Thought\n",
    "We first experiment with the Chain-of-Thought method.\n",
    "Since we are having the simplest generation algorithm, we directly ask the model to generate all the steps.\n",
    "We look at the 4-shot prompt and the generated answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6a467a187f55cf03",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am playing with a set of blocks where I need to arrange the blocks into stacks. Here are the actions I can do\n",
      "\n",
      "Pick up a block\n",
      "Unstack a block from on top of another block\n",
      "Put down a block\n",
      "Stack a block on top of another block\n",
      "\n",
      "I have the following restrictions on my actions:\n",
      "I can only pick up or unstack one block at a time.\n",
      "I can only pick up or unstack a block if my hand is empty.\n",
      "I can only pick up a block if the block is on the table and the block is clear. A block is clear if the block has no other blocks on top of it and if the block is not picked up.\n",
      "I can only unstack a block from on top of another block if the block I am unstacking was really on top of the other block.\n",
      "I can only unstack a block from on top of another block if the block I am unstacking is clear.\n",
      "Once I pick up or unstack a block, I am holding the block.\n",
      "I can only put down a block that I am holding.\n",
      "I can only stack a block on top of another block if I am holding the block being stacked.\n",
      "I can only stack a block on top of another block if the block onto which I am stacking the block is clear.\n",
      "Once I put down or stack a block, my hand becomes empty.\n",
      "\n",
      "[STATEMENT]\n",
      "As initial conditions I have that, the red block is clear, the orange block is clear, the hand is empty, the orange block is on top of the blue block, the red block is on the table and the blue block is on the table.\n",
      "My goal is to have that the blue block is on top of the orange block.\n",
      "\n",
      "My plan is as follows:\n",
      "\n",
      "[PLAN]\n",
      "unstack the orange block from on top of the blue block\n",
      "put down the orange block\n",
      "pick up the blue block\n",
      "stack the blue block on top of the orange block\n",
      "[PLAN END]\n",
      "\n",
      "[STATEMENT]\n",
      "As initial conditions I have that, the blue block is clear, the orange block is clear, the hand is empty, the red block is on top of the yellow block, the orange block is on top of the red block, the blue block is on the table and the yellow block is on the table.\n",
      "My goal is to have that the blue block is on top of the yellow block and the orange block is on top of the blue block.\n",
      "\n",
      "My plan is as follows:\n",
      "\n",
      "[PLAN]\n",
      "unstack the orange block from on top of the red block\n",
      "put down the orange block\n",
      "unstack the red block from on top of the yellow block\n",
      "put down the red block\n",
      "pick up the blue block\n",
      "stack the blue block on top of the yellow block\n",
      "pick up the orange block\n",
      "stack the orange block on top of the blue block\n",
      "[PLAN END]\n",
      "\n",
      "[STATEMENT]\n",
      "As initial conditions I have that, the red block is clear, the yellow block is clear, the hand is empty, the red block is on top of the blue block, the blue block is on top of the orange block, the orange block is on the table and the yellow block is on the table.\n",
      "My goal is to have that the blue block is on top of the orange block and the yellow block is on top of the red block.\n",
      "\n",
      "My plan is as follows:\n",
      "\n",
      "[PLAN]\n",
      "pick up the yellow block\n",
      "stack the yellow block on top of the red block\n",
      "[PLAN END]\n",
      "\n",
      "[STATEMENT]\n",
      "As initial conditions I have that, the blue block is clear, the yellow block is clear, the hand is empty, the red block is on top of the orange block, the blue block is on top of the red block, the orange block is on the table and the yellow block is on the table.\n",
      "My goal is to have that the blue block is on top of the red block and the yellow block is on top of the blue block.\n",
      "\n",
      "My plan is as follows:\n",
      "\n",
      "[PLAN]\n",
      "pick up the yellow block\n",
      "stack the yellow block on top of the blue block\n",
      "[PLAN END]\n",
      "\n",
      "[STATEMENT]\n",
      "As initial conditions I have that, the blue block is clear, the orange block is clear, the hand is empty, the orange block is on top of the red block, the red block is on the table and the blue block is on the table\n",
      "My goal is to the red block is on top of the blue block\n",
      "\n",
      "My plan is as follows:\n",
      "\n",
      "[PLAN]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cot_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "933ffa650264c50b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 23:09:50,999 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "output = model.generate([cot_inputs],\n",
    "                        hide_input=True,\n",
    "                        eos_token_id='\\n[').text[0][:].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "acde323347b1eb9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pick up the orange block  \n",
      "put down the orange block (onto the table)  \n",
      "pick up the red block  \n",
      "stack the red block on top of the blue block  \n",
      "[PLAN END]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d7795",
   "metadata": {},
   "source": [
    "Clearly that's not a valid solution :( \n",
    "The orange block is on the red block, so we cannot pick up the red block as the first step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e258cb3",
   "metadata": {},
   "source": [
    "## Tree-of-Thought\n",
    "Then let's turn to a tree search algorithm, [Tree-of-Thought]((https://arxiv.org/abs/2305.10601)).\n",
    "We will need to define a simple world model, and a search algorithm, for the Blocksworld task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ffaa93bb6ee24586",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from reasoners import WorldModel, LanguageModel, SearchConfig, State, Reasoner\n",
    "from reasoners.algorithm import BeamSearch, MCTS\n",
    "import reasoners.benchmark.bw_utils as utils\n",
    "from typing import NamedTuple\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "class SelfEval(BaseModel):\n",
    "    action_to_eval_and_context: str = Field(description=\"Action to evaluate and the context for evaluation\")\n",
    "    justification: str = Field(description=\"Justification for self eval\")\n",
    "    self_eval_value: str = Field(description=\"Self eval (good or bad)\")\n",
    "    self_eval_score: float = Field(description=\"Self eval score between 1 and 10. Where 0 is extremely bad and 10 is extremely good\")\n",
    "\n",
    "self_eval_parser = JsonOutputParser(pydantic_object=SelfEval)\n",
    "\n",
    "# We use NamedTuple for clearer presentation, you may just use normal tuple if you want a quick experiment.\n",
    "class BWStateToT(NamedTuple):\n",
    "    step_idx: int\n",
    "    action_history: list[str]\n",
    "    end: bool\n",
    "\n",
    "\n",
    "# We just use the description str as the action, we use a type alias for better presentation.\n",
    "# You may directly use str of you want a quick experiment.\n",
    "BWAction = str\n",
    "\n",
    "\n",
    "class BlocksWorldModelToT(WorldModel):\n",
    "    def __init__(self,\n",
    "                 base_model: LanguageModel,\n",
    "                 prompt: dict,\n",
    "                 max_steps: int = 4,\n",
    "                 batch_size: int = 1) -> None:\n",
    "        super().__init__()\n",
    "        self.max_steps = max_steps\n",
    "        self.base_model = base_model\n",
    "        self.prompt = prompt\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def init_state(self) -> BWStateToT:\n",
    "        return BWStateToT(step_idx=0, action_history=[], end=False)\n",
    "    \n",
    "    def step(self, state: BWStateToT, action: BWAction) -> tuple[BWStateToT, dict]:\n",
    "        state = copy.deepcopy(state)\n",
    "        if action != \"[PLAN END]\":\n",
    "            state = BWStateToT(step_idx=state.step_idx + 1, action_history=state.action_history + [action], end=False)\n",
    "        else:\n",
    "            state = BWStateToT(step_idx=state.step_idx + 1, action_history=state.action_history, end=True)\n",
    "        return state, {}  # the dict is auxiliary information for SearchConfig, we don't need it here.\n",
    "    \n",
    "    def is_terminal(self, state: State) -> bool:\n",
    "        return state.end or state.step_idx >= self.max_steps\n",
    "\n",
    "\n",
    "class BWConfigToT(SearchConfig):\n",
    "    def __init__(self,\n",
    "                 base_model: LanguageModel,\n",
    "                 prompt: dict,\n",
    "                 temperature: float = 0.8,\n",
    "                 n_candidate: int = 4) -> None:\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.example = None\n",
    "        self.prompt = prompt\n",
    "        self.n_candidate = n_candidate\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def get_actions(self, state: BWStateToT) -> list[BWAction]:\n",
    "        prompts = (self.prompt[\"icl\"]\n",
    "                       .replace(\"<action>\", \"\\n\".join(state.action_history + [\"\"]))\n",
    "                       .replace(\"<init_state>\", utils.extract_init_state(self.example))\n",
    "                       .replace(\"<goals>\", utils.extract_goals(self.example, return_raw=True)))\n",
    "        system_prompt = \"\"\"\n",
    "        You are a helpful assistant that generates the best possible next action based on the current state and goals.\n",
    "        You must output the next action as a sentence, and nothing else.\n",
    "        When you are unable to generate a valid action, you should output \"[PLAN END]\".\n",
    "        \"\"\"\n",
    "        outputs = self.base_model.generate([prompts],\n",
    "                                           num_return_sequences=self.n_candidate,\n",
    "                                           max_length=20,\n",
    "                                           eos_token_id=\"\\n\",\n",
    "                                           temperature=self.temperature,\n",
    "                                           do_sample=True,\n",
    "                                           hide_input=True,\n",
    "                                           system_prompt=system_prompt).text\n",
    "        outputs = [output.split(\"\\n\")[0] for output in outputs]\n",
    "        outputs = list(dict.fromkeys(outputs))  # deduplicate\n",
    "        print(outputs)\n",
    "        return outputs\n",
    "\n",
    "    # Some reward functions are fast to calculate.\n",
    "    # We calculate the reward before executing the action, which can be used to better guide the search.\n",
    "    def fast_reward(self, state: BWStateToT, action: BWAction) -> tuple[float, dict]:\n",
    "        # We use two rewards here:\n",
    "        # 1. Intuition: The loglikelihood of the action given the prompt.\n",
    "        # 2. Self-eval: Ask the language model whether this step is \"Good\".\n",
    "        # inputs = self.prompt[\"icl\"].replace(\"<action>\", \"\\n\".join(state.action_history + [\"\"])) \\\n",
    "        #     .replace(\"<init_state>\", utils.extract_init_state(self.example)) \\\n",
    "        #     .replace(\"<goals>\", utils.extract_goals(self.example, return_raw=True))[:-1]\n",
    "        \n",
    "        # intuition = self.base_model.get_loglikelihood(inputs, [inputs + \"\\n\" + action])[0]\n",
    "\n",
    "        self_eval_prompt = (self.prompt[\"self-eval\"].replace(\"<init_state>\", utils.extract_init_state(self.example))\n",
    "                                                    .replace(\"<goals>\", utils.extract_goals(self.example, return_raw=True))\n",
    "                                                    .replace(\"<action>\", action))\n",
    "        system_prompt = \"\"\"You are a helpful assistant that evaluates the quality of a given action.\n",
    "                        You will be given a context and an action, and you need to evaluate the action.\n",
    "                        You need to provide a justification for your evaluation, and a score between 1 and 10.\n",
    "                        Where 0 is extremely bad and 10 is extremely good. \n",
    "                        You must follow the following format: \"\"\" + self_eval_parser.get_format_instructions()\n",
    "        self_eval = self.base_model.generate([self_eval_prompt], \n",
    "                                             system_prompt=system_prompt)\n",
    "        # print(self_eval)\n",
    "        self_eval = self_eval_parser.parse(self_eval.text[0])\n",
    "        self_eval_score = self_eval['self_eval_score']\n",
    "        # print(self_eval)\n",
    "        # self_eval = self.base_model.get_loglikelihood(self_eval_prompt, [self_eval_prompt + \"good\"])[0]\n",
    "\n",
    "        return self_eval, {\"self_eval\": self_eval_score}\n",
    "    \n",
    "    # kwargs is the auxiliary information returned by SearchConfig.fast_reward and WorldModel.step,\n",
    "    # so that we do not need duplicated calculations.\n",
    "    # In this case, we just use the fast_reward result as the reward.\n",
    "    # Generally, if a reward function depends on the new state, or is slow to calculate,\n",
    "    # we will calculate it here.\n",
    "    def reward(self, state, action, **kwargs) -> tuple[float, dict]:\n",
    "        return kwargs['self_eval'], kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f623a38d",
   "metadata": {},
   "source": [
    "Note: The following command may take to 2 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9b3b2bec8947b3e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 23:09:01,745 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unstack the orange block from on top of the red block']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 23:09:06,397 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:09:10,555 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['put down the orange block']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 23:09:22,022 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:09:25,502 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pick up the red block']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 23:09:31,441 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:09:35,025 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stack the red block on top of the blue block']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 23:09:43,104 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BeamSearchResult(terminal_node=<reasoners.algorithm.beam_search.BeamSearchNode object at 0x17582e3b0>, terminal_state=BWStateToT(step_idx=4, action_history=['unstack the orange block from on top of the red block', 'put down the orange block', 'pick up the red block', 'stack the red block on top of the blue block'], end=False), cum_reward=3, tree=<reasoners.algorithm.beam_search.BeamSearchNode object at 0x17cff5960>, trace=[(None, BWStateToT(step_idx=0, action_history=[], end=False), 0.0), ('unstack the orange block from on top of the red block', BWStateToT(step_idx=1, action_history=['unstack the orange block from on top of the red block'], end=False), 9), ('put down the orange block', BWStateToT(step_idx=2, action_history=['unstack the orange block from on top of the red block', 'put down the orange block'], end=False), 5), ('pick up the red block', BWStateToT(step_idx=3, action_history=['unstack the orange block from on top of the red block', 'put down the orange block', 'pick up the red block'], end=False), 2), ('stack the red block on top of the blue block', BWStateToT(step_idx=4, action_history=['unstack the orange block from on top of the red block', 'put down the orange block', 'pick up the red block', 'stack the red block on top of the blue block'], end=False), 3)])\n"
     ]
    }
   ],
   "source": [
    "world_model = BlocksWorldModelToT(base_model=model, prompt=prompt)\n",
    "config = BWConfigToT(base_model=model, prompt=prompt)\n",
    "algorithm = BeamSearch(beam_size=4, max_depth=7)\n",
    "reasoner_tot = Reasoner(world_model=world_model, search_config=config, search_algo=algorithm)\n",
    "result_tot = reasoner_tot(example)\n",
    "print(result_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ad2fc8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action, Reward\n",
      "None 0.0\n",
      "unstack the orange block from on top of the red block 9\n",
      "put down the orange block 5\n",
      "pick up the red block 2\n",
      "stack the red block on top of the blue block 3\n"
     ]
    }
   ],
   "source": [
    "print('Action, Reward')\n",
    "for action, _, reward in result_tot.trace:\n",
    "    print(action, reward)\n",
    "\n",
    "# Action, Reward\n",
    "# None 0.0\n",
    "# pick up the red block -0.4957015\n",
    "# stack the red block on top of the blue block -1.0114484\n",
    "# [PLAN END] -0.78032136"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccf2a76",
   "metadata": {},
   "source": [
    "Still the same error :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093768cbd94dbee",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## RAP\n",
    "With [RAP](https://arxiv.org/abs/2305.14992), we are truly using the latest block configuration as the state, instead of a history of actions.\n",
    "Thus, we define a new world model to transit between states, which is just a little complex than the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4db36c24eab92e95",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BWAction = str\n",
    "\n",
    "\n",
    "class BWStateRAP(NamedTuple):\n",
    "    step_idx: int\n",
    "    last_blocks_state: str\n",
    "    blocks_state: str\n",
    "    buffered_action: BWAction\n",
    "\n",
    "\n",
    "class BlocksWorldModelRAP(WorldModel):\n",
    "    def __init__(self,\n",
    "                 base_model: LanguageModel,\n",
    "                 prompt: dict,\n",
    "                 max_steps: int = 4,\n",
    "                 batch_size: int = 1) -> None:\n",
    "        super().__init__()\n",
    "        self.max_steps = max_steps\n",
    "        self.base_model = base_model\n",
    "        self.prompt = prompt\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def init_state(self) -> BWStateRAP:\n",
    "        return BWStateRAP(step_idx=0, last_blocks_state=\"\", blocks_state=utils.\n",
    "                       extract_init_state(self.example), buffered_action=\"\")\n",
    "\n",
    "    def step(self, state: BWStateRAP, action: BWAction) -> tuple[BWStateRAP, dict]:\n",
    "        state = copy.deepcopy(state)\n",
    "        blocks_state = state.blocks_state\n",
    "        step_idx = state.step_idx\n",
    "        blocks_state = self.update_blocks(blocks_state, action)\n",
    "        new_buffered_action = action if state.buffered_action == \"\" else \"\"\n",
    "\n",
    "        state = BWStateRAP(step_idx=step_idx + 1,\n",
    "                        last_blocks_state=state.blocks_state,\n",
    "                        blocks_state=blocks_state,\n",
    "                        buffered_action=new_buffered_action)\n",
    "        return state, {\"goal_reached\": utils.goal_check(utils.extract_goals(self.example), blocks_state)}\n",
    "\n",
    "    def update_blocks(self, block_states: str, action: BWAction) -> str:\n",
    "        if \"pick\" in action:\n",
    "            key = \"world_update_pickup\"\n",
    "        elif \"unstack\" in action:\n",
    "            key = \"world_update_unstack\"\n",
    "        elif \"put\" in action:\n",
    "            key = \"world_update_putdown\"\n",
    "        elif \"stack\" in action:\n",
    "            key = \"world_update_stack\"\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action\")\n",
    "        \n",
    "        world_update_prompt = self.prompt[key].format(block_states, action.capitalize() + \".\")\n",
    "        system_prompt = \"\"\"\n",
    "            <Task Instructions> \n",
    "                Given a world state and action, describe only the resulting state changes.\n",
    "                Follow the examples provided for context.\n",
    "                Be detailed and specific in your description.\n",
    "            </Task Instructions>\n",
    "\n",
    "            <Output Format>\n",
    "                Output should be plain text sentences describing the changes, with no additional formatting.\n",
    "            </Output Format>\n",
    "        \"\"\"\n",
    "        world_output = self.base_model.generate([world_update_prompt],\n",
    "                                                system_prompt=system_prompt,\n",
    "                                                eos_token_id=\"\\n\",\n",
    "                                                hide_input=True,\n",
    "                                                temperature=0, \n",
    "                                                ).text[0].strip()\n",
    "        # print(world_output)\n",
    "        new_state = utils.apply_change(world_output, block_states)\n",
    "        return new_state\n",
    "\n",
    "    def is_terminal(self, state: BWStateRAP) -> bool:\n",
    "        if utils.goal_check(utils.extract_goals(self.example), state.blocks_state)[0]:\n",
    "            return True\n",
    "        elif state.step_idx == self.max_steps:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "884e9c962952d37b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BWConfigRAP(SearchConfig):\n",
    "    def __init__(self,\n",
    "                 base_model: LanguageModel,\n",
    "                 prompt: dict,\n",
    "                 batch_size: int = 1,\n",
    "                 reward_alpha: float = 0.5,\n",
    "                 goal_reward_default: float = 0.,\n",
    "                 goal_reached_reward: float = 100.) -> None:\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.example = None\n",
    "        self.prompt = prompt\n",
    "        self.batch_size = batch_size\n",
    "        self.reward_alpha = reward_alpha\n",
    "        self.goal_reward_default = goal_reward_default\n",
    "        self.goal_reached_reward = goal_reached_reward\n",
    "\n",
    "    def get_actions(self, state: BWStateRAP) -> list[BWAction]:\n",
    "        blocks_state = state.blocks_state\n",
    "        return utils.generate_all_actions(blocks_state)\n",
    "\n",
    "    def fast_reward(self, state: BWStateRAP, action: BWAction) -> tuple[float, dict]:\n",
    "        if state.buffered_action == \"\":\n",
    "            current_blocks_state = state.blocks_state\n",
    "        else:\n",
    "            current_blocks_state = state.last_blocks_state\n",
    "        # previous_action = state.buffered_action + \"\\n\" if state.buffered_action != \"\" else \"\"\n",
    "        \n",
    "        # every two steps, we will also reduce the icl examples by 2 steps\n",
    "        # so that the distribution of step length in examples is more reasonable\n",
    "        # icl_template = self.prompt[\"icl_list\"][state.step_idx // 2]\n",
    "        \n",
    "        # inputs = (icl_template.replace(\"<init_state>\", current_blocks_state)\n",
    "        #                       .replace(\"<goals>\", utils.extract_goals(self.example, return_raw=True))\n",
    "        #                       .replace(\"<action>\", previous_action))\n",
    "        # intuition = self.base_model.get_loglikelihood(inputs, [inputs + action])[0]\n",
    "\n",
    "        self_eval_prompt = (self.prompt[\"self-eval\"]\n",
    "                                .replace(\"<init_state>\", current_blocks_state)\n",
    "                                .replace(\"<goals>\", utils.extract_goals(self.example, return_raw=True))\n",
    "                                .replace(\"<action>\", action))\n",
    "        system_prompt = f\"\"\"\n",
    "                        <Task Instructions>\n",
    "                            You must evaluate the quality of the given action.\n",
    "                        You will be given the necessary context and an action, and you need to evaluate the action.\n",
    "                        You should evaluate the last action taken and the current world state. \n",
    "                        Everything before that is context.\n",
    "                        You should evaluate the likelihood of the action being able to achieve the goal.\n",
    "                        You need to provide a justification for your evaluation, and a score between 1 and 10.\n",
    "                        Where 0 is extremely bad and 10 is extremely good. \n",
    "                        </Task Instructions>\n",
    "                        \n",
    "                        <Output Format>\n",
    "                        {self_eval_parser.get_format_instructions()}\n",
    "                        </Output Format>\n",
    "                        \"\"\"\n",
    "        self_eval = self.base_model.generate([self_eval_prompt], \n",
    "                                             system_prompt=system_prompt)\n",
    "        self_eval = self_eval_parser.parse(self_eval.text[0])\n",
    "        self_eval_score = self_eval['self_eval_score']\n",
    "\n",
    "        return (self.calculate_reward(self_eval_score),\n",
    "                {\"self_eval\": self_eval_score})\n",
    "        # self_eval = self.base_model.get_loglikelihood(self_eval_prompt, [self_eval_prompt + \"good\"])[0]\n",
    "\n",
    "        # return (self.calculate_reward(intuition, self_eval),\n",
    "        #         {'intuition': intuition, \"self_eval\": self_eval})\n",
    "\n",
    "    def calculate_reward(self, self_eval, goal_reached=None) -> float:\n",
    "        # to provide a unified interface for reward and fast_reward\n",
    "        if goal_reached is None:\n",
    "            goal_reward = self.goal_reward_default\n",
    "        elif goal_reached[0]:\n",
    "            goal_reward = self.goal_reached_reward\n",
    "        else:\n",
    "            goal_reward = goal_reached[1]\n",
    "        return (self_eval) * self.reward_alpha + goal_reward * (1 - self.reward_alpha)\n",
    "\n",
    "    def reward(self, state: BWStateRAP, action: BWAction,\n",
    "               intuition: float = None,\n",
    "               self_eval: float = None,\n",
    "               goal_reached: tuple[bool, float] = None) -> tuple[float, dict]:\n",
    "        return (self.calculate_reward(self_eval, goal_reached),\n",
    "                {'goal_reached': goal_reached})\n",
    "\n",
    "    # def calculate_reward(self, intuition, self_eval, goal_reached=None) -> float:\n",
    "    #     # to provide a unified interface for reward and fast_reward\n",
    "    #     if goal_reached is None:\n",
    "    #         goal_reward = self.goal_reward_default\n",
    "    #     elif goal_reached[0]:\n",
    "    #         goal_reward = self.goal_reached_reward\n",
    "    #     else:\n",
    "    #         goal_reward = goal_reached[1]\n",
    "    #     return (intuition + self_eval) * self.reward_alpha + goal_reward * (1 - self.reward_alpha)\n",
    "\n",
    "    # def reward(self, state: BWStateRAP, action: BWAction,\n",
    "    #            intuition: float = None,\n",
    "    #            self_eval: float = None,\n",
    "    #            goal_reached: tuple[bool, float] = None) -> tuple[float, dict]:\n",
    "    #     return (self.calculate_reward(intuition, self_eval, goal_reached),\n",
    "    #             {'intuition': intuition, 'goal_reached': goal_reached})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a97d5bdf453a8e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We just use the MCTS algorithm embedded in Reasoners, and build up the pipeline again.\n",
    "Note: the following command may take 2 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "70e0d64c166c5ccc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCTS iteration:   0%|          | 0/10 [00:00<?, ?it/s]2024-11-27 23:07:01,016 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:07:07,162 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:07:11,153 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:07:17,891 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:07:24,017 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:07:29,277 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:07:32,897 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:07:40,433 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:07:45,149 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:07:52,504 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:07:56,210 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:08:03,674 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:08:10,108 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:08:15,869 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "2024-11-27 23:08:19,965 - INFO - HTTP Request: POST https://lumnis.openai.azure.com//openai/deployments/gpt-4o-us-east-1/chat/completions?api-version=2024-03-01-preview \"HTTP/1.1 200 OK\"\n",
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCTSResult(terminal_state=BWStateRAP(step_idx=4, last_blocks_state='the blue block is clear, the orange block is clear, the red block is in the hand, the hand is holding the red block, the blue block is on the table, and the orange block is on the table.', blocks_state='the orange block is clear, the red block is clear, the hand is empty, the red block is on top of the blue block, the blue block is on the table, and the orange block is on the table.', buffered_action=''), cum_reward=62.5, trace=([BWStateRAP(step_idx=0, last_blocks_state='', blocks_state='the blue block is clear, the orange block is clear, the hand is empty, the orange block is on top of the red block, the red block is on the table and the blue block is on the table.', buffered_action=''), BWStateRAP(step_idx=1, last_blocks_state='the blue block is clear, the orange block is clear, the hand is empty, the orange block is on top of the red block, the red block is on the table and the blue block is on the table.', blocks_state='the blue block is clear, the orange block is in the hand, the red block is clear, the hand is holding the orange block, the blue block is on the table, and the red block is on the table.', buffered_action='unstack the orange block from on top of the red block'), BWStateRAP(step_idx=2, last_blocks_state='the blue block is clear, the orange block is in the hand, the red block is clear, the hand is holding the orange block, the blue block is on the table, and the red block is on the table.', blocks_state='the blue block is clear, the orange block is clear, the red block is clear, the hand is empty, the blue block is on the table, the orange block is on the table, and the red block is on the table.', buffered_action=''), BWStateRAP(step_idx=3, last_blocks_state='the blue block is clear, the orange block is clear, the red block is clear, the hand is empty, the blue block is on the table, the orange block is on the table, and the red block is on the table.', blocks_state='the blue block is clear, the orange block is clear, the red block is in the hand, the hand is holding the red block, the blue block is on the table, and the orange block is on the table.', buffered_action='pick up the red block'), BWStateRAP(step_idx=4, last_blocks_state='the blue block is clear, the orange block is clear, the red block is in the hand, the hand is holding the red block, the blue block is on the table, and the orange block is on the table.', blocks_state='the orange block is clear, the red block is clear, the hand is empty, the red block is on top of the blue block, the blue block is on the table, and the orange block is on the table.', buffered_action='')], ['unstack the orange block from on top of the red block', 'put down the orange block', 'pick up the red block', 'stack the red block on top of the blue block']), trace_of_nodes=[<reasoners.algorithm.mcts.MCTSNode object at 0x178af5240>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c6530>, <reasoners.algorithm.mcts.MCTSNode object at 0x175840f10>, <reasoners.algorithm.mcts.MCTSNode object at 0x1758438b0>, <reasoners.algorithm.mcts.MCTSNode object at 0x1758412d0>], tree_state=<reasoners.algorithm.mcts.MCTSNode object at 0x178af5240>, trace_in_each_iter=[[<reasoners.algorithm.mcts.MCTSNode object at 0x178825c00>, <reasoners.algorithm.mcts.MCTSNode object at 0x1756029b0>, <reasoners.algorithm.mcts.MCTSNode object at 0x175866a40>, <reasoners.algorithm.mcts.MCTSNode object at 0x1758650c0>, <reasoners.algorithm.mcts.MCTSNode object at 0x175864d30>], [<reasoners.algorithm.mcts.MCTSNode object at 0x1755a8340>, <reasoners.algorithm.mcts.MCTSNode object at 0x17cff7ac0>, <reasoners.algorithm.mcts.MCTSNode object at 0x17cff7eb0>, <reasoners.algorithm.mcts.MCTSNode object at 0x175867910>, <reasoners.algorithm.mcts.MCTSNode object at 0x175864310>], [<reasoners.algorithm.mcts.MCTSNode object at 0x1755c48b0>, <reasoners.algorithm.mcts.MCTSNode object at 0x17cff4850>, <reasoners.algorithm.mcts.MCTSNode object at 0x175865690>, <reasoners.algorithm.mcts.MCTSNode object at 0x175865780>, <reasoners.algorithm.mcts.MCTSNode object at 0x175866710>], [<reasoners.algorithm.mcts.MCTSNode object at 0x1758439d0>, <reasoners.algorithm.mcts.MCTSNode object at 0x175867010>, <reasoners.algorithm.mcts.MCTSNode object at 0x175864ac0>, <reasoners.algorithm.mcts.MCTSNode object at 0x175865cf0>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c1f60>], [<reasoners.algorithm.mcts.MCTSNode object at 0x175840850>, <reasoners.algorithm.mcts.MCTSNode object at 0x175867640>, <reasoners.algorithm.mcts.MCTSNode object at 0x175866c20>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c28f0>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c28c0>], [<reasoners.algorithm.mcts.MCTSNode object at 0x17cff5060>, <reasoners.algorithm.mcts.MCTSNode object at 0x175864220>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c3310>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c2fe0>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c2c80>], [<reasoners.algorithm.mcts.MCTSNode object at 0x17cff6fe0>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c3580>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c2620>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c32e0>, <reasoners.algorithm.mcts.MCTSNode object at 0x175859180>], [<reasoners.algorithm.mcts.MCTSNode object at 0x175865ae0>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c3190>, <reasoners.algorithm.mcts.MCTSNode object at 0x175841900>, <reasoners.algorithm.mcts.MCTSNode object at 0x175840d00>, <reasoners.algorithm.mcts.MCTSNode object at 0x175842a10>], [<reasoners.algorithm.mcts.MCTSNode object at 0x1755c1cf0>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c3e50>, <reasoners.algorithm.mcts.MCTSNode object at 0x175843fd0>, <reasoners.algorithm.mcts.MCTSNode object at 0x175840790>, <reasoners.algorithm.mcts.MCTSNode object at 0x175841fc0>], [<reasoners.algorithm.mcts.MCTSNode object at 0x1755c2c50>, <reasoners.algorithm.mcts.MCTSNode object at 0x1758420e0>, <reasoners.algorithm.mcts.MCTSNode object at 0x175841300>, <reasoners.algorithm.mcts.MCTSNode object at 0x175843c10>, <reasoners.algorithm.mcts.MCTSNode object at 0x175843700>]], tree_state_after_each_iter=[<reasoners.algorithm.mcts.MCTSNode object at 0x178825c00>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755a8340>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c48b0>, <reasoners.algorithm.mcts.MCTSNode object at 0x1758439d0>, <reasoners.algorithm.mcts.MCTSNode object at 0x175840850>, <reasoners.algorithm.mcts.MCTSNode object at 0x17cff5060>, <reasoners.algorithm.mcts.MCTSNode object at 0x17cff6fe0>, <reasoners.algorithm.mcts.MCTSNode object at 0x175865ae0>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c1cf0>, <reasoners.algorithm.mcts.MCTSNode object at 0x1755c2c50>], aggregated_result=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "world_model = BlocksWorldModelRAP(base_model=model, prompt=prompt, max_steps=4)\n",
    "config = BWConfigRAP(base_model=model, prompt=prompt)\n",
    "algorithm = MCTS(depth_limit=4, disable_tqdm=False, output_trace_in_each_iter=True, n_iters=10)\n",
    "reasoner_rap = Reasoner(world_model=world_model, search_config=config, search_algo=algorithm)\n",
    "result_rap = reasoner_rap(example)\n",
    "print(result_rap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3f540139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([BWStateRAP(step_idx=0, last_blocks_state='', blocks_state='the blue block is clear, the orange block is clear, the hand is empty, the orange block is on top of the red block, the red block is on the table and the blue block is on the table.', buffered_action=''),\n",
       "  BWStateRAP(step_idx=1, last_blocks_state='the blue block is clear, the orange block is clear, the hand is empty, the orange block is on top of the red block, the red block is on the table and the blue block is on the table.', blocks_state='the blue block is clear, the orange block is in the hand, the red block is clear, the hand is holding the orange block, the blue block is on the table, and the red block is on the table.', buffered_action='unstack the orange block from on top of the red block'),\n",
       "  BWStateRAP(step_idx=2, last_blocks_state='the blue block is clear, the orange block is in the hand, the red block is clear, the hand is holding the orange block, the blue block is on the table, and the red block is on the table.', blocks_state='the blue block is clear, the orange block is clear, the red block is clear, the hand is empty, the blue block is on the table, the orange block is on the table, and the red block is on the table.', buffered_action=''),\n",
       "  BWStateRAP(step_idx=3, last_blocks_state='the blue block is clear, the orange block is clear, the red block is clear, the hand is empty, the blue block is on the table, the orange block is on the table, and the red block is on the table.', blocks_state='the blue block is clear, the orange block is clear, the red block is in the hand, the hand is holding the red block, the blue block is on the table, and the orange block is on the table.', buffered_action='pick up the red block'),\n",
       "  BWStateRAP(step_idx=4, last_blocks_state='the blue block is clear, the orange block is clear, the red block is in the hand, the hand is holding the red block, the blue block is on the table, and the orange block is on the table.', blocks_state='the orange block is clear, the red block is clear, the hand is empty, the red block is on top of the blue block, the blue block is on the table, and the orange block is on the table.', buffered_action='')],\n",
       " ['unstack the orange block from on top of the red block',\n",
       "  'put down the orange block',\n",
       "  'pick up the red block',\n",
       "  'stack the red block on top of the blue block'])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ([BWStateRAP(step_idx=0, last_blocks_state='', blocks_state='the blue block is clear, the orange block is clear, the hand is empty, the orange block is on top of the red block, the red block is on the table and the blue block is on the table.', buffered_action=''),\n",
    "#   BWStateRAP(step_idx=1, last_blocks_state='the blue block is clear, the orange block is clear, the hand is empty, the orange block is on top of the red block, the red block is on the table and the blue block is on the table.', blocks_state='the blue block is clear, the orange block is in the hand, the red block is clear, the hand is holding the orange block, the blue block is on the table, and the red block is on the table.', buffered_action='unstack the orange block from on top of the red block'),\n",
    "#   BWStateRAP(step_idx=2, last_blocks_state='the blue block is clear, the orange block is in the hand, the red block is clear, the hand is holding the orange block, the blue block is on the table, and the red block is on the table.', blocks_state='the blue block is clear, the orange block is clear, the red block is clear, the hand is empty, the blue block is on the table, the orange block is on the table, and the red block is on the table.', buffered_action=''),\n",
    "#   BWStateRAP(step_idx=3, last_blocks_state='the blue block is clear, the orange block is clear, the red block is clear, the hand is empty, the blue block is on the table, the orange block is on the table, and the red block is on the table.', blocks_state='the blue block is clear, the orange block is clear, the red block is in the hand, the hand is holding the red block, the blue block is on the table, and the orange block is on the table.', buffered_action='pick up the red block'),\n",
    "#   BWStateRAP(step_idx=4, last_blocks_state='the blue block is clear, the orange block is clear, the red block is in the hand, the hand is holding the red block, the blue block is on the table, and the orange block is on the table.', blocks_state='the orange block is clear, the red block is clear, the hand is empty, the red block is on top of the blue block, the blue block is on the table, and the orange block is on the table.', buffered_action='')],\n",
    "#  ['unstack the orange block from on top of the red block',\n",
    "#   'put down the orange block',\n",
    "#   'pick up the red block',\n",
    "#   'stack the red block on top of the blue block'])\n",
    "result_rap.trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f52fa",
   "metadata": {},
   "source": [
    "Finally, we get a valid solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e6c930da69ea10",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a685a07",
   "metadata": {},
   "source": [
    "Visualization is as simple as calling `visualize(log)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "eb852e28f78e630c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-11T05:19:20.380716Z",
     "start_time": "2024-03-11T05:19:19.723124Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizer URL: https://www.llm-reasoners.net/visualizer/111cdc51-4aac-4ad6-a094-9761a388b50b?accessKey=23ba0af5\n"
     ]
    }
   ],
   "source": [
    "from reasoners.visualization import visualize\n",
    "from reasoners.visualization.tree_snapshot import NodeData, EdgeData\n",
    "from reasoners.algorithm.mcts import MCTSNode\n",
    "\n",
    "\n",
    "# (Optional) You can write node_data_factory and edge_data_factory to show customized information.\n",
    "def blocksworld_node_data_factory(n: MCTSNode) -> NodeData:\n",
    "    return NodeData({\"block state\": n.state.blocks_state if n.state else \"Not expanded\",\n",
    "                     \"# goals satisfied\": n.reward_details[\"goal_reached\"][1] if hasattr(n, \"reward_details\") else \"N/A\",\n",
    "                     \"# visited\": len(n.cum_rewards)})\n",
    "\n",
    "def blocksworld_edge_data_factory(n: MCTSNode) -> EdgeData:\n",
    "    return EdgeData({\"Q\": n.Q,\n",
    "                    #  \"intuition\": n.fast_reward_details[\"intuition\"],\n",
    "                     \"self_eval\": n.fast_reward_details[\"self_eval\"],\n",
    "                     \"action\": n.action})\n",
    "\n",
    "visualize(result_rap,\n",
    "          node_data_factory=blocksworld_node_data_factory,\n",
    "          edge_data_factory=blocksworld_edge_data_factory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadf5ab5",
   "metadata": {},
   "source": [
    "This evaluator module provides standard APIs and easy implementation of multiple popular reasoning datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ab27669adac79b8d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'prompts/pool_prompt_v1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompts/pool_prompt_v1.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      3\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m BWEvaluator(config_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexamples/CoT/blocksworld/data/bw_config.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                         domain_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexamples/CoT/blocksworld/data/generated_domain.pddl\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                         data_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexamples/CoT/blocksworld/data/split_v1/split_v1_step_4_data.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                         init_prompt\u001b[38;5;241m=\u001b[39mprompt)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/reasoners/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'prompts/pool_prompt_v1.json'"
     ]
    }
   ],
   "source": [
    "with open('prompts/pool_prompt_v1.json') as f:\n",
    "    prompt = json.load(f)\n",
    "evaluator = BWEvaluator(config_file='examples/CoT/blocksworld/data/bw_config.yaml',\n",
    "                        domain_file='examples/CoT/blocksworld/data/generated_domain.pddl',\n",
    "                        data_path='examples/CoT/blocksworld/data/split_v1/split_v1_step_4_data.json',\n",
    "                        init_prompt=prompt)\n",
    "evaluator.evaluate(reasoner_tot, shuffle_prompt=True, num_shot=4, resume=0, log_dir='log/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036a78e95ef7ce8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
